{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c27f812",
   "metadata": {},
   "source": [
    "# Week 3 Tutorial (Solutions) - Probability Review, Distribution Approximation and Divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4a4fe",
   "metadata": {},
   "source": [
    "### Authors: Rajit Rajpal, Kirill Tamogashev, Nikolay Malkin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ea791",
   "metadata": {},
   "source": [
    "We will aim to fit data using GMMs by optimizing Forward KL (zero-avoiding, mass-covering) and Reverse KL (zero-forcing, mode-seeking).\n",
    "`# TODO` are for you to implement. Solutions will contain the completed code.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction & Setup\n",
    "\n",
    "In this tutorial, we will explore how to approximate a complex **Target** distribution (**P**) using a simpler **Model** distribution (**Q**). We will visualize why different divergence measures (Forward KL, Reverse KL) lead to different approximations.\n",
    "\n",
    "### The Setup\n",
    "\n",
    "- **Target (P):** A fixed Gaussian Mixture Model (GMM) with 4 components.\n",
    "- **Model (Q\\_θ):** A learnable GMM. We will try to learn the parameters θ (means, covariances, weights).\n",
    "\n",
    "### 1.1 Imports and Data\n",
    "\n",
    "First, let's define our ground truth data parameters.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we install some useful packages\n",
    "%pip install numpy matplotlib torch scipy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee1cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target defined with 4 components.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- The Target Distribution P(x) ---\n",
    "# We define a GMM with 4 components\n",
    "means_data = torch.tensor([[0.5,0], [3,2], [-1,1], [2,-1]]) * 2\n",
    "covs_data = torch.tensor([[[1,0],[0,1]], [[1,0.5],[0.5,1]], [[1,-0.5],[-0.5,1]], [[0.5,0],[0,4]]])\n",
    "covs_data[1] *= 1\n",
    "weights_data = torch.tensor([0.2, 0.3, 0.2, 0.3])\n",
    "\n",
    "print(\"Target defined with 4 components.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4fabd",
   "metadata": {},
   "source": [
    "## 2. The Computational Graph: Sampling and Density\n",
    "\n",
    "To perform computations, we need two fundamental operations for our GMM:\n",
    "\n",
    "- **Sampling:**  \n",
    "  $$ x \\sim P(x) $$\n",
    "\n",
    "- **Density Evaluation:**  \n",
    "  $$ p(x) $$\n",
    "\n",
    "### Exercise 1: Implement GMM Density\n",
    "\n",
    "The probability density of a GMM is the weighted sum of its component densities:\n",
    "\n",
    "$$\n",
    "p(x) = \\sum_{k=1}^{K} \\pi_k \\, \\mathcal{N}(x \\mid \\mu_k, \\Sigma_k)\n",
    "$$\n",
    "\n",
    "Complete the function below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_sample(means, covs, weights, n):\n",
    "    \"\"\"\n",
    "    Samples n points from a GMM.\n",
    "    \"\"\"\n",
    "    n = int(n)\n",
    "    # 1. Sample component indices according to weights (Categorical)\n",
    "    indices = torch.multinomial(weights, n, replacement=True)\n",
    "    \n",
    "    # 2. Sample from the specific Gaussian components\n",
    "    # (Here we sample from all and select, effective for batching)\n",
    "    samples = torch.zeros((n, 2))\n",
    "    for i in range(len(means)):\n",
    "        # Create a batch of samples for this component\n",
    "        # We use numpy for standard sampling here, but torch.distributions is also valid\n",
    "        comp_samples = np.random.multivariate_normal(means[i].detach().numpy(), covs[i].detach().numpy(), n)\n",
    "        samples[indices == i] = torch.from_numpy(comp_samples[indices == i]).float()\n",
    "    return samples\n",
    "\n",
    "def gmm_density(X, means=means_data, covs=covs_data, weights=weights_data):\n",
    "    \"\"\"\n",
    "    Computes p(x) for a batch of points X.\n",
    "    \"\"\"\n",
    "    # X shape: (Batch, 2)\n",
    "    density = torch.zeros(X.shape[0])\n",
    "    \n",
    "    for i in range(len(means)):\n",
    "        \n",
    "        diff = X - means[i]\n",
    "        # Calculate Mahalanobis distance term\n",
    "        inv_cov = torch.linalg.inv(covs[i])\n",
    "         # TODO: Calculate the multivariate gaussian density for component i\n",
    "        # Hint: You can use the formula:\n",
    "        # exp(-0.5 * (x-mu)^T Sigma^-1 (x-mu)) / sqrt((2pi)^k |Sigma|)\n",
    "        exponent = -0.5 * torch.sum(..., axis=1)\n",
    "        \n",
    "        # Calculate Normalization constant\n",
    "        norm_const = torch.sqrt((2 * np.pi)**2 * torch.det(covs[i]))\n",
    "        \n",
    "        # Add weighted probability to total density\n",
    "        prob_i = torch.exp(exponent) / norm_const\n",
    "        density += weights[i] * prob_i\n",
    "        \n",
    "    return density\n",
    "\n",
    "# --- Visualization Code (Do not modify) ---\n",
    "def plot_density(means, covs, weights, title=\"Density\"):\n",
    "    XX, YY = torch.meshgrid(torch.linspace(-5, 10, 150), torch.linspace(-7, 8, 150), indexing='xy')\n",
    "    grid_x = torch.stack([XX.reshape(-1), YY.reshape(-1)], dim=1)\n",
    "    d = gmm_density(grid_x, means, covs, weights).reshape(150, 150)\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(d.T, extent=(-5, 10, -7, 8), origin='lower', cmap='Reds')\n",
    "    plt.title(title)\n",
    "    plt.xlim(-5, 10); plt.ylim(-7, 8)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "plot_density(means_data, covs_data, weights_data, \"Target Distribution P(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a7aef",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Estimation\n",
    "\n",
    "We often cannot calculate integrals like entropy\n",
    "\n",
    "$$\n",
    "H(P) = -\\int p(x)\\log p(x)\\,dx = \\mathbb{E}_{x \\sim P}[\\log p(x)]\n",
    "$$\n",
    "\n",
    "analytically. \n",
    "\n",
    "Instead, we use Monte Carlo estimation:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x \\sim P}[f(x)] \\approx \\frac{1}{N}\\sum_{i=1}^{N} f(x_i)\n",
    "\\quad \\text{where } x_i \\sim P(x)\n",
    "$$\n",
    "\n",
    "### Exercise 2: Estimate KL Divergence\n",
    "\n",
    "We need to measure the distance between two distributions. The **Forward KL** is defined as:\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P \\| Q) = \\mathbb{E}_{x \\sim P}[\\log \\frac{P(x)}{Q(x)}]\n",
    "$$\n",
    "\n",
    "Implement the estimator below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_kl_forward(means_p, covs_p, weights_p, means_q, covs_q, weights_q, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Estimates KL(P || Q) using samples from P.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 1. Sample from P\n",
    "        samples = gmm_sample(means_p, covs_p, weights_p, n_samples)\n",
    "        \n",
    "        # 2. Evaluate densities\n",
    "        p_density = gmm_density(samples, means_p, covs_p, weights_p)\n",
    "        q_density = gmm_density(samples, means_q, covs_q, weights_q)\n",
    "        \n",
    "        # 3. Compute Monte Carlo Estimator\n",
    "        # TODO: Return the mean difference of log densities, you can use torch.log()\n",
    "        kl = torch.mean(...)\n",
    "        \n",
    "    return kl.item()\n",
    "\n",
    "# Test with P against itself (Should be approx 0)\n",
    "print(f\"KL(P||P) approx: {estimate_kl_forward(means_data, covs_data, weights_data, means_data, covs_data, weights_data):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c2831",
   "metadata": {},
   "source": [
    "## 4. Optimization: Fitting the Model\n",
    "\n",
    "Now we will define a learnable model $ Q_\\theta $. We will parameterize the covariance using a factorization\n",
    "\n",
    "$$\n",
    "\\Sigma = A A^{T}\n",
    "$$\n",
    "\n",
    "to ensure it remains positive semi-definite (Cholesky decomposition).\n",
    "\n",
    "The parameters of the GMM are: $$\\theta = (\\mu_k, \\Sigma_k, w_k)$$ for $k \\in \\{1,..,n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de9ec9",
   "metadata": {},
   "source": [
    "### Exercise 3: Forward KL (MLE)\n",
    "\n",
    "**Objective:** Minimize\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P \\| Q_\\theta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\mathrm{FKL}} = \\mathbb{E}_{x \\sim P}[\\log P(x) - \\log Q_\\theta(x)]\n",
    "$$\n",
    "\n",
    "Since $$ \\mathbb{E}_{x \\sim P}[\\log P(x)] $$ is constant with respect to θ, minimizing Forward KL is equivalent to **Maximizing Likelihood (MLE)**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} \\approx -\\frac{1}{N}\\sum_{i=1}^{N} \\log Q_\\theta(x_i)\n",
    "\\quad \\text{where } x_i \\sim P_{\\text{data}}\n",
    "$$\n",
    "##### Remember that maximizing log-likelihood is equivalent to minimizing negative log-likelihood (NLL) which is more suitable as a loss to minimize. Therefore, the function below will return the NLL.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fkl(means_m, covs_m, weights_m, means_t, covs_t, weights_t, n_samples=500):\n",
    "    \"\"\" Minimize KL(P || Q) -> Maximize E_p[log Q] \"\"\"\n",
    "    # 1. Sample from Target P (fixed)\n",
    "    x_p = gmm_sample(means_t, covs_t, weights_t, n_samples)\n",
    "    \n",
    "    # 2. Evaluate Model probability Q on these samples\n",
    "    q_on_p = gmm_density(x_p, means_m, covs_m, weights_m)\n",
    "    \n",
    "    # 3. TODO: Loss = Negative Log Likelihood. We add 1e-10 to avoid log(0) error.\n",
    "    loss = -torch.mean(torch.log(... + 1e-10))\n",
    "    return loss\n",
    "\n",
    "# Test with P against itself (Should be approx 4-4.5)\n",
    "print(f\"NLL approx: {compute_fkl(means_data, covs_data, weights_data, means_data, covs_data, weights_data):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef1a76",
   "metadata": {},
   "source": [
    "### Exercise 4: Reverse KL (Mode Seeking)\n",
    "\n",
    "**Objective:** Minimize\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(Q_\\theta \\| P)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\mathrm{RKL}} = \\mathbb{E}_{x \\sim Q_\\theta}\n",
    "[\\log Q_\\theta(x) - \\log P(x)]\n",
    "$$\n",
    "\n",
    "The issue with this is that $\\nabla_{\\theta} \\mathcal{L}(\\theta)$ cannot be computed directly using standard backpropagation because the expectation is taken over samples $x$ drawn from $Q_{\\theta}$, and the sampling operation is non-differentiable. To overcome this, we use the Score Function Estimator (often called REINFORCE in reinforcement learning). We rely on the \"Log-Derivative Trick\" identity: $$\\nabla_{\\theta} Q_{\\theta}(x) = Q_{\\theta}(x)\\nabla_{\\theta} \\log Q_{\\theta}(x)$$.\n",
    "\n",
    "Applying this to the gradient of the expectation: $$\\nabla_{\\theta} \\mathcal{L}(\\theta) = \\mathbb{E}_{x \\sim Q_{\\theta}}[\n",
    "\\underbrace{\\big(\\log Q_{\\theta}(x) - \\log P(x)\\big)}_{\\text{score/reward}}\\;\\cdot\\;\\nabla_{\\theta} \\log Q_{\\theta}(x)]$$\n",
    "\n",
    "You may use a Monte-Carlo expectation to approximate the above expectation. Note that this is widely known to be quite high-variance and unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rkl(means_m, covs_m, weights_m, means_t, covs_t, weights_t, n_samples=500):\n",
    "    \"\"\" Minimize KL(Q || P)\"\"\"\n",
    "    # 1. Sample from Model Q (No grad for sampling location in this simple setup)\n",
    "    with torch.no_grad():\n",
    "        x_q = gmm_sample(means_m, covs_m, weights_m, n_samples)\n",
    "    \n",
    "    # 2. Evaluate densities\n",
    "    q_x = gmm_density(x_q, means_m, covs_m, weights_m)\n",
    "    p_x = gmm_density(x_q, means_t, covs_t, weights_t)\n",
    "    \n",
    "    # 3. Compute Loss\n",
    "    # We use the identity: grad(E_q[f]) = E_q[f * grad(log q)]\n",
    "    # Here f = log q - log p\n",
    "    log_q = torch.log(q_x + 1e-10)\n",
    "    log_p = torch.log(p_x + 1e-10)\n",
    "    \n",
    "    # The term in brackets is the \"reward/score\", we detach it so it's treated as a constant scalar\n",
    "    score = (...).detach() # TODO: Implement the score/reward.\n",
    "    loss = (...).mean() # TODO: Implement the loss using the score defined above.\n",
    "    return loss\n",
    "\n",
    "# Test with P against itself (Should be approx 0)\n",
    "print(f\"Loss approx: {compute_rkl(means_data, covs_data, weights_data, means_data, covs_data, weights_data):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8e3ba",
   "metadata": {},
   "source": [
    "## Time to get training!\n",
    "This will fit the GMM using 1-4 components for forward KL and reverse KL. Nothing to implement here, just run it! It should take upto a minute to train each objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8713a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Training Helper (Returns parameters instead of plotting) ---\n",
    "def train_gmm_parameters(loss_fn, n_comps, iterations=5000):\n",
    "    # Initialize Parameters\n",
    "    means_model = torch.randn((n_comps, 2), requires_grad=True)\n",
    "    sqcovs_model = torch.stack([torch.eye(2) for _ in range(n_comps)])\n",
    "    sqcovs_model.requires_grad_(True)\n",
    "    weights_logits = torch.zeros(n_comps, requires_grad=True)\n",
    "\n",
    "    opt = torch.optim.Adam([means_model, sqcovs_model, weights_logits], lr=0.01)\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        current_covs = sqcovs_model @ sqcovs_model.transpose(-1, -2)\n",
    "        current_weights = torch.softmax(weights_logits, dim=0)\n",
    "        \n",
    "        # Accessing global data variables (means_data, covs_data, weights_data)\n",
    "        loss = loss_fn(means_model, current_covs, current_weights, \n",
    "                       means_data, covs_data, weights_data)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    final_covs = sqcovs_model @ sqcovs_model.transpose(-1, -2)\n",
    "    final_weights = torch.softmax(weights_logits, dim=0)\n",
    "    \n",
    "    return means_model.detach(), final_covs.detach(), final_weights.detach()\n",
    "\n",
    "# --- Experiment Runner (Ground Truth + Optimize 1-4) ---\n",
    "def run_experiment_row(loss_fn, title_prefix):\n",
    "    print(f\"--- Running Experiments: {title_prefix} ---\")\n",
    "    \n",
    "    # 1. Train models for n=1 to 4\n",
    "    results = []\n",
    "    component_counts = [1, 2, 3, 4]\n",
    "    \n",
    "    for n in component_counts:\n",
    "        params = train_gmm_parameters(loss_fn, n_comps=n)\n",
    "        results.append(params)\n",
    "\n",
    "    # 2. Visualization (1 Row, 5 Cols: GT + 4 Results)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "    fig.suptitle(f\"{title_prefix}\", fontsize=16)\n",
    "\n",
    "    # Common Grid Generation\n",
    "    with torch.no_grad():\n",
    "        XX, YY = torch.meshgrid(torch.linspace(-5, 10, 150), torch.linspace(-7, 8, 150), indexing='xy')\n",
    "        grid_x = torch.stack([XX.reshape(-1), YY.reshape(-1)], dim=1)\n",
    "        \n",
    "        # --- Column 1: Ground Truth ---\n",
    "        d_gt = gmm_density(grid_x, means_data, covs_data, weights_data).reshape(150, 150)\n",
    "        axes[0].imshow(d_gt.T, extent=(-5, 10, -7, 8), origin='lower', cmap='Reds')\n",
    "        axes[0].set_title(\"Ground Truth\")\n",
    "        axes[0].set_xlim(-5, 10); axes[0].set_ylim(-7, 8)\n",
    "        axes[0].set_xticks([]); axes[0].set_yticks([])\n",
    "\n",
    "        # --- Columns 2-5: Optimization Results ---\n",
    "        for i, (n, (means, covs, weights)) in enumerate(zip(component_counts, results)):\n",
    "            ax = axes[i + 1] # Shift index right by 1 to make room for GT\n",
    "            \n",
    "            # Compute density\n",
    "            d = gmm_density(grid_x, means, covs, weights).reshape(150, 150)\n",
    "            \n",
    "            # Plot\n",
    "            ax.imshow(d.T, extent=(-5, 10, -7, 8), origin='lower', cmap='Reds')\n",
    "            ax.set_title(f\"{n} Component{'s' if n > 1 else ''}\")\n",
    "            ax.set_xlim(-5, 10); ax.set_ylim(-7, 8)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Run Experiments ---\n",
    "run_experiment_row(compute_fkl, \"Forward KL (MLE)\")\n",
    "run_experiment_row(compute_rkl, \"Reverse KL (Mode Seeking)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11c743",
   "metadata": {},
   "source": [
    "## 5. Discussion Questions\n",
    "\n",
    "**Forward KL (MLE):**  \n",
    "Look at the result of `fkl`. Does the model distribution cover all 4 components of the target? Why does it create *bridges* of probability density between the modes?\n",
    "\n",
    "*Hint:* What is the penalty for $ Q(x) \\approx 0 $ where $ P(x) > 0 $?\n",
    "\n",
    "**Reverse KL:**  \n",
    "Look at the result of `rkl`. Why does it collapse to a single mode?\n",
    "\n",
    "*Hint:* What happens if $ Q(x) $ is wide and covers areas where $ P(x) \\approx 0 $?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c89b94",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
